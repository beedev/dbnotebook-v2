# ============================================
# Plugin Architecture Configuration (MVP 5)
# ============================================
# LLM Provider (ollama|openai|anthropic)
LLM_PROVIDER=ollama

# LLM Model (provider-specific)
LLM_MODEL=llama3.1:latest

# Embedding Provider (huggingface)
EMBEDDING_PROVIDER=huggingface

# Embedding Model
EMBEDDING_MODEL=nomic-ai/nomic-embed-text-v1.5

# Retrieval Strategy (hybrid|semantic|keyword)
RETRIEVAL_STRATEGY=hybrid

# ============================================
# LLM Provider API Keys
# ============================================
# Anthropic API key (optional - for Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google Gemini API key (optional - for Gemini models)
GOOGLE_API_KEY=your_google_api_key_here

# OpenAI API key (optional - for OpenAI models)
OPENAI_API_KEY=your_openai_api_key_here

# ============================================
# Model Configuration (configurable defaults)
# ============================================
# Default LLM model to use on startup (legacy - use LLM_MODEL above)
DEFAULT_LLM_MODEL=llama3.1:latest

# Default embedding model (legacy - use EMBEDDING_MODEL above)
DEFAULT_EMBEDDING_MODEL=nomic-ai/nomic-embed-text-v1.5

# ============================================
# Model Provider Settings
# ============================================
# Anthropic (Claude) settings
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_TEMPERATURE=0.7
ANTHROPIC_MAX_TOKENS=4096

# Gemini settings
GEMINI_MODEL=gemini-2.0-flash-exp
GEMINI_TEMPERATURE=0.7
GEMINI_MAX_OUTPUT_TOKENS=4096

# OpenAI settings
OPENAI_MODEL=gpt-4-turbo
OPENAI_TEMPERATURE=0.7

# Ollama settings
OLLAMA_HOST=localhost
OLLAMA_PORT=11434

# ============================================
# Image Generation Configuration (Imagen / Gemini)
# ============================================
# Image generation provider (gemini)
IMAGE_GENERATION_PROVIDER=gemini

# Gemini/Imagen Image Generation settings (uses GOOGLE_API_KEY from above)
# Models (Imagen):
#   imagen-4.0-generate-001 - Production quality (default)
#   imagen-4.0-fast-generate-001 - Faster, lower quality
#   imagen-4.0-ultra-generate-001 - Highest quality
# Models (Gemini/Nano Banana):
#   gemini-2.0-flash-exp - Nano Banana, fast experimental
#   gemini-3-pro-image-preview - Nano Banana Pro, higher quality 4K
GEMINI_IMAGE_MODEL=imagen-4.0-generate-001

# Output directory for generated images
IMAGE_OUTPUT_DIR=outputs/images

# Maximum image file size in MB
MAX_IMAGE_SIZE_MB=10

# Supported image formats (comma-separated)
SUPPORTED_IMAGE_FORMATS=jpg,jpeg,png,webp

# ============================================
# Vision Model Configuration
# ============================================
# Enable vision models for image processing (true|false)
USE_VISION_FOR_IMAGES=false

# Default vision model to use
VISION_MODEL=gpt-4-vision-preview

# Available vision models (for UI dropdown)
VISION_MODELS=gpt-4-vision-preview,claude-3-5-sonnet-20241022,gemini-1.5-pro-vision

# ============================================
# Document Management
# ============================================
# Persist documents in vector DB (true|false)
PERSIST_DOCUMENTS=true

# Maximum documents per user/session
MAX_DOCUMENTS=100

# Document storage path
DOCUMENT_STORAGE_PATH=data/documents

# Auto-activate new documents (true|false)
AUTO_ACTIVATE_DOCUMENTS=false

# ============================================
# AWS Configuration (for Textract OCR fallback)
# ============================================
AWS_ACCESS_KEY_ID=your_aws_access_key_here
AWS_SECRET_ACCESS_KEY=your_aws_secret_key_here
AWS_DEFAULT_REGION=us-east-1
