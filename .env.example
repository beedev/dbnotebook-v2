# ============================================
# Plugin Architecture Configuration (MVP 5)
# ============================================
# LLM Provider (ollama|openai|anthropic)
LLM_PROVIDER=ollama

# LLM Model (provider-specific)
LLM_MODEL=llama3.1:latest

# Embedding Provider (huggingface)
EMBEDDING_PROVIDER=huggingface

# Embedding Model
EMBEDDING_MODEL=nomic-ai/nomic-embed-text-v1.5

# Retrieval Strategy (hybrid|semantic|keyword)
RETRIEVAL_STRATEGY=hybrid

# ============================================
# LLM Provider API Keys
# ============================================
# Anthropic API key (optional - for Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google Gemini API key (optional - for Gemini models)
GOOGLE_API_KEY=your_google_api_key_here

# OpenAI API key (optional - for OpenAI models)
OPENAI_API_KEY=your_openai_api_key_here

# ============================================
# Model Configuration (configurable defaults)
# ============================================
# Default LLM model to use on startup (legacy - use LLM_MODEL above)
DEFAULT_LLM_MODEL=llama3.1:latest

# Default embedding model (legacy - use EMBEDDING_MODEL above)
DEFAULT_EMBEDDING_MODEL=nomic-ai/nomic-embed-text-v1.5

# ============================================
# Model Provider Settings
# ============================================
# Anthropic (Claude) settings
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_TEMPERATURE=0.7
ANTHROPIC_MAX_TOKENS=4096

# Gemini settings
GEMINI_MODEL=gemini-2.0-flash-exp
GEMINI_TEMPERATURE=0.7
GEMINI_MAX_OUTPUT_TOKENS=4096

# OpenAI settings
OPENAI_MODEL=gpt-4-turbo
OPENAI_TEMPERATURE=0.7

# Ollama settings
OLLAMA_HOST=localhost
OLLAMA_PORT=11434

# ============================================
# Context Window Configuration
# ============================================
# Ollama model context window (how much the model can "see")
# llama3.1 supports up to 128K, default is 128000
CONTEXT_WINDOW=128000

# Chat memory buffer limit (for conversation history + retrieved context)
# This limits the tokens used for chat memory, default is 32000
# Increase for longer conversations, decrease for faster responses
CHAT_TOKEN_LIMIT=32000

# ============================================
# Image Generation Configuration (Imagen / Gemini)
# ============================================
# Image generation provider (gemini)
IMAGE_GENERATION_PROVIDER=gemini

# Gemini/Imagen Image Generation settings (uses GOOGLE_API_KEY from above)
# Models (Imagen):
#   imagen-4.0-generate-001 - Production quality (default)
#   imagen-4.0-fast-generate-001 - Faster, lower quality
#   imagen-4.0-ultra-generate-001 - Highest quality
# Models (Gemini/Nano Banana):
#   gemini-2.0-flash-exp - Nano Banana, fast experimental
#   gemini-3-pro-image-preview - Nano Banana Pro, higher quality 4K
GEMINI_IMAGE_MODEL=imagen-4.0-generate-001

# Output directory for generated images
IMAGE_OUTPUT_DIR=outputs/images

# Maximum image file size in MB
MAX_IMAGE_SIZE_MB=10

# Supported image formats (comma-separated)
SUPPORTED_IMAGE_FORMATS=jpg,jpeg,png,webp

# ============================================
# Vision Model Configuration (Image Understanding)
# ============================================
# Vision provider for image understanding (gemini|openai)
VISION_PROVIDER=gemini

# Gemini Vision model (uses GOOGLE_API_KEY from above)
GEMINI_VISION_MODEL=gemini-2.0-flash-exp

# OpenAI Vision model (uses OPENAI_API_KEY from above)
OPENAI_VISION_MODEL=gpt-4o

# ============================================
# Web Content Integration (Firecrawl + Jina)
# ============================================
# Firecrawl API key for web search (required for search feature)
FIRECRAWL_API_KEY=your_firecrawl_api_key_here

# Jina API key for higher rate limits (optional)
# Without API key: 20 RPM, With API key: 200 RPM
JINA_API_KEY=your_jina_api_key_here

# ============================================
# PostgreSQL Configuration
# ============================================
POSTGRES_HOST=localhost
POSTGRES_PORT=5433
POSTGRES_DB=dbnotebook_dev
POSTGRES_USER=dbnotebook
POSTGRES_PASSWORD=dbnotebook

# Full DATABASE_URL (alternative to individual settings)
# DATABASE_URL=postgresql://dbnotebook:dbnotebook@localhost:5433/dbnotebook_dev

# ============================================
# pgvector Configuration
# ============================================
# Embedding dimension (768 for HuggingFace nomic, 1536 for OpenAI)
# IMPORTANT: Set this BEFORE first migration - cannot be changed after DB is created
PGVECTOR_EMBED_DIM=768

# Table name for embeddings
PGVECTOR_TABLE_NAME=data_embeddings

# ============================================
# SQL Chat (Chat with Data) Configuration
# ============================================
# Encryption key for storing database passwords securely
# Generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
# IMPORTANT: Set this for persistent connection storage across restarts
SQL_CHAT_ENCRYPTION_KEY=

# Skip read-only access check for database connections (DEV MODE ONLY)
# Set to "true" to allow connections with write access (useful for testing)
# WARNING: In production, always use read-only database users for security
SQL_CHAT_SKIP_READONLY_CHECK=true

# Max examples to load from Gretel dataset (default: 100000)
# Use smaller value for faster testing, full dataset for production
FEW_SHOT_MAX_EXAMPLES=100000
