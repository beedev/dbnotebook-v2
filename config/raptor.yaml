# =============================================================================
# RAPTOR Configuration
# Recursive Abstractive Processing for Tree-Organized Retrieval
# Reference: https://arxiv.org/abs/2401.18059
# =============================================================================

# -----------------------------------------------------------------------------
# CLUSTERING (GMM + UMAP)
# Controls how chunks are grouped into semantic clusters
# -----------------------------------------------------------------------------
clustering:
  # UMAP dimensionality reduction
  umap_n_components: 10       # Target dimensions after reduction
  umap_n_neighbors: 15        # Local neighborhood size for UMAP
  umap_min_dist: 0.1          # Minimum distance between points in embedding
  umap_metric: "cosine"       # Distance metric for UMAP

  # GMM clustering
  gmm_probability_threshold: 0.3  # Min probability for soft cluster membership
  min_cluster_size: 3         # Minimum nodes per cluster
  max_cluster_size: 10        # Maximum nodes per cluster (split if larger)
  max_clusters: 50            # Maximum clusters per level (safety limit)

  # Clustering behavior
  random_state: 42            # For reproducibility
  n_init: 10                  # GMM initialization attempts

# -----------------------------------------------------------------------------
# SUMMARIZATION
# Controls LLM-based cluster summarization
# -----------------------------------------------------------------------------
summarization:
  # Token limits
  max_input_tokens: 6000      # Max tokens for chunks being summarized
  summary_max_tokens: 500     # Max tokens for generated summary
  max_chunks_per_summary: 10  # Max chunks to include in one summary

  # LLM prompts - CRITICAL: These prompts must preserve numerical values and tabular data
  cluster_summary_prompt: |
    You are an expert summarizer. Below are related text chunks from a document that have been grouped together by semantic similarity.

    Create a comprehensive summary that:
    1. Captures the main themes and key points across all chunks
    2. **CRITICAL: Preserve ALL numerical values exactly as written** (amounts like 150, 300, 500, percentages, limits, thresholds, dates, IDs)
    3. **CRITICAL: When you encounter tables or eligibility matrices, list the specific values for each category/row**
       - Format: "[Category/Level]: [field1]=value1, [field2]=value2, ..."
       - Example: "L1-L3 employees: local_conveyance=150, per_diem=500, private_arrangement=200"
    4. Maintains logical flow and coherence
    5. Is self-contained and understandable without the original chunks

    IMPORTANT: Do NOT summarize numbers as "varies" or "depends on level" - always include the actual specific values.

    CHUNKS TO SUMMARIZE:
    {chunks}

    COMPREHENSIVE SUMMARY:

  root_summary_prompt: |
    You are an expert summarizer. Below are summaries from different sections of a document.

    Create a high-level executive summary that:
    1. Provides an overview of the entire document's content
    2. Highlights the most important themes and conclusions
    3. **CRITICAL: Preserve ALL specific numerical values from the summaries below** (amounts, percentages, limits, thresholds)
    4. **CRITICAL: If the summaries contain tabular data or eligibility information with specific values, include them**
       - List specific values rather than generalizing
       - Example: "Travel allowances by level: L1-L3 (local_conveyance=150), L4-L7 (local_conveyance=250), L8-L10 (local_conveyance=300)"
    5. Notes any key relationships between different sections

    IMPORTANT: Numerical precision is required. Do NOT replace specific values with general statements.

    SECTION SUMMARIES:
    {summaries}

    DOCUMENT SUMMARY:

# -----------------------------------------------------------------------------
# TREE BUILDING
# Controls RAPTOR tree construction
# -----------------------------------------------------------------------------
tree_building:
  max_tree_depth: 4           # Maximum levels in the tree (0=chunks, 1-3=summaries)
  min_nodes_to_cluster: 5     # Minimum nodes needed to create a new level
  batch_size: 50              # Nodes to process in one batch
  embedding_batch_size: 8     # Embeddings to generate at once
  max_concurrent_summaries: 3 # Parallel LLM calls for summarization
  max_retries: 3              # Retry failed operations
  retry_delay_seconds: 1.0    # Delay between retries

# -----------------------------------------------------------------------------
# RETRIEVAL
# Controls RAPTOR-aware retrieval behavior
# -----------------------------------------------------------------------------
retrieval:
  # Level selection for different query types
  # Always include L0 chunks since they contain the actual content
  summary_query_levels: [0, 1, 2, 3]  # All levels - summaries boost ranking
  detail_query_levels: [0, 1]          # L0 chunks + L1 cluster summaries

  # Intent detection keywords (used as fallback if LLM unavailable)
  summary_keywords:
    - "summarize"
    - "summary"
    - "overview"
    - "main points"
    - "key takeaways"
    - "themes"
    - "gist"
    - "brief"
    - "what is this about"
    - "tldr"
    - "highlights"
    - "main ideas"
    - "general idea"
    - "big picture"

  detail_keywords:
    - "specific"
    - "detail"
    - "exactly"
    - "quote"
    - "what does it say about"
    - "where"
    - "when"
    - "how many"
    - "what is the"
    - "explain"
    - "section"
    - "page"
    - "paragraph"

  # Retrieval parameters
  top_k_per_level: 6          # Results to retrieve per tree level
  rerank_top_k: 6             # Final results after reranking
  min_similarity_threshold: 0.3  # Minimum similarity for inclusion

  # Score boosting for level-aware retrieval
  summary_level_boost: 1.5    # Boost for higher-level nodes in summary queries
  detail_level_boost: 1.3     # Boost for level-0 nodes in detail queries

  # Hybrid retrieval (BM25 + Vector fusion)
  use_hybrid_retrieval: true
  bm25_weight: 0.5            # Weight for BM25 keyword matching (0.0-1.0)
  vector_weight: 0.5          # Weight for vector semantic search (0.0-1.0)
  num_query_variations: 3     # Generate query variations for better coverage

# -----------------------------------------------------------------------------
# FEATURE FLAGS
# -----------------------------------------------------------------------------
enabled: true                 # Enable RAPTOR processing
auto_build_on_upload: true    # Auto-build tree after document upload
fallback_to_flat_retrieval: true  # Use flat retrieval if tree not built

# -----------------------------------------------------------------------------
# QUALITY PRESETS
# Pre-configured settings for different use cases
# -----------------------------------------------------------------------------
presets:
  fast:
    # Optimized for speed - fewer clusters, smaller summaries
    tree_building:
      max_tree_depth: 2
      min_nodes_to_cluster: 8
    clustering:
      max_cluster_size: 15
    summarization:
      summary_max_tokens: 300
      max_chunks_per_summary: 15

  balanced:
    # Default settings - uses values above

  thorough:
    # Maximum quality - more clusters, detailed summaries
    tree_building:
      max_tree_depth: 5
      min_nodes_to_cluster: 3
    clustering:
      min_cluster_size: 2
      max_cluster_size: 6
      gmm_probability_threshold: 0.2
    summarization:
      summary_max_tokens: 800
      max_chunks_per_summary: 6
